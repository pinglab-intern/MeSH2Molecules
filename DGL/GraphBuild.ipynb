{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value means srcID, dstID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch as th\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'disease': 2, 'drug': 3, 'gene': 4},\n",
       "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 2},\n",
       "      metagraph=[('drug', 'drug'), ('drug', 'gene'), ('drug', 'disease')])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a heterograph with 3 node types and 3 edges types.\n",
    "graph_data = {\n",
    "    ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 0])),\n",
    "    ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
    "    ('drug', 'treats', 'disease'): (th.tensor([1, 2]), th.tensor([1, 0]))\n",
    "}\n",
    "g = dgl.heterograph(graph_data)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = h5py.File('./mesh_path.h5','r')\n",
    "f2 = h5py.File('./path_reac.h5','r')\n",
    "f3 = h5py.File('./reac_reac.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1 = f1['src']\n",
    "src2 = f2['src']\n",
    "src3 = f3['src']\n",
    "dis1 = f1['dis']\n",
    "dis2 = f2['dis']\n",
    "dis3 = f3['dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'meshDescriptor': 121, 'pathway': 209, 'reaction': 1277},\n",
       "      num_edges={('meshDescriptor', 'hasEvent', 'pathway'): 345, ('pathway', 'hasEvent', 'reaction'): 1289, ('reaction', 'precedingEvent', 'reaction'): 955},\n",
       "      metagraph=[('meshDescriptor', 'pathway'), ('pathway', 'reaction'), ('reaction', 'reaction')])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data = {\n",
    "    ('meshDescriptor', 'hasEvent', 'pathway'): (th.tensor(src1), th.tensor(dis1)),\n",
    "    ('pathway', 'hasEvent', 'reaction'): (th.tensor(src2), th.tensor(dis2)),\n",
    "    ('reaction', 'precedingEvent', 'reaction'): (th.tensor(src3), th.tensor(dis3))\n",
    "}\n",
    "G = dgl.heterograph(graph_data)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.nodes('pathway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node types: ['meshDescriptor', 'pathway', 'reaction']\n",
      "Edge types: ['hasEvent', 'hasEvent', 'precedingEvent']\n",
      "Canonical edge types: [('meshDescriptor', 'hasEvent', 'pathway'), ('pathway', 'hasEvent', 'reaction'), ('reaction', 'precedingEvent', 'reaction')]\n"
     ]
    }
   ],
   "source": [
    "print('Node types:', G.ntypes)\n",
    "print('Edge types:', G.etypes)\n",
    "print('Canonical edge types:', G.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"label_pathway\": shape (209,), type \"<i8\">"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f4 = h5py.File('./label_path.h5','r')\n",
    "label_pathway = f4['label_pathway']\n",
    "label_pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0, 117,   0, 117,  58,   0, 102,  14, 117, 117,   1,   2,  10,\n",
       "          2,  39,  40,  14,  74, 110,  26, 107,  14,  75,  11,  19,  73,  59,\n",
       "          8,  11,  62,   9,  62,  97,   9,   9,   9,   9,  12,  11,  28,  45,\n",
       "         11,  26,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  45,  26,\n",
       "         11,  11,  24,  11,  11,  45,  75,  11,  26,  86,  73,  11,  75,  11,\n",
       "         86,  14, 109,  14,  39, 100,  14,  58,  14,  14, 104,  19,  19,  31,\n",
       "        119,  21,  25,  25,  26,  26,  26,  26,  45,  28,  40,  28,  29,  33,\n",
       "         33,  33,  33,  75,  38,  39,  40, 102,  40,  40,  40,  63,  95,  41,\n",
       "         41,  43,  93,  97,  97,  49,  67,  53,  54,  89,  89,  57, 120,  58,\n",
       "         67,  58,  58, 103,  58,  58, 102,  69,  58,  60,  60,  62,  62,  62,\n",
       "         63,  65,  65,  65,  67,  67,  67,  67,  67,  67,  67,  67,  67,  67,\n",
       "         67,  67,  67,  67,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,\n",
       "         75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  93,  93,\n",
       "         78,  93,  85,  86,  93,  88,  88,  88,  91,  96,  96,  96,  97,  97,\n",
       "         97,  97,  97,  97,  98, 111, 111, 111, 102, 102, 104, 106, 108])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pathway = torch.tensor(label_pathway).long()\n",
    "len(label_pathway)\n",
    "labels = label_pathway\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = list(range(209))\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:180]).long()\n",
    "val_idx = torch.tensor(shuffle[160:200]).long()\n",
    "test_idx = torch.tensor(shuffle[200:]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "    def forward(self, G, feat_dict):\n",
    "        #input输入是每一种节点特征的字典 \n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # 计算 W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # 将其存入图中以便于信息传递\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # 指定每个关系的消息传递函数：（message_func，reduce_func）。\n",
    "            # 请注意，结果将保存到相同的目标特征“ h”，这暗示了聚合的类型明智的约简。\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # 触发多种类型的消息传递。\n",
    "        # 第一个参数是每个关系的消息传递函数（message passing functions）\n",
    "        # 第二个是类型明智的reduce functions，可以是“ sum”，“ max”，“ min”，“ mean”，“ stack”\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # 返回更新的节点特征（以字典形式表示）\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # 使用可训练的节点嵌入作为无特征输入。\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        # 创建神经网络层\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        #获取文章预测结果\n",
    "        return h_dict['paper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import urllib.request\n",
    "\n",
    "#data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "#data_file_path = '/tmp/ACM.mat'\n",
    "\n",
    "#urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat('./ACM.mat')\n",
    "print(list(data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data['PvsA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n",
      "      num_edges={('paper', 'written-by', 'author'): 37055, ('author', 'writing', 'paper'): 37055, ('paper', 'citing', 'paper'): 30789, ('paper', 'cited', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('subject', 'has', 'paper'): 12499},\n",
      "      metagraph=[('author', 'paper'), ('paper', 'author'), ('paper', 'paper'), ('paper', 'paper'), ('paper', 'subject'), ('subject', 'paper')])\n"
     ]
    }
   ],
   "source": [
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'],\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'],\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'],\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose(),\n",
    "    })\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 graphviz创建元图.\n",
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')\n",
    "plot_graph(g.metagraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 10805, 10806, 12420], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvc = data['PvsC'].tocsr()\n",
    "# 找到所有在 KDD, ICML, VLDB三个会议论文上发表的文章\n",
    "c_selected = [0, 11, 13]  # 三个数字分别代表KDD, ICML, VLDB\n",
    "p_selected = pvc[:, c_selected].tocoo() # 选出在\n",
    "\n",
    "# 生成标记\n",
    "labels = pvc.indices\n",
    "labels[labels == 11] = 1\n",
    "labels[labels == 13] = 2\n",
    "labels = torch.tensor(labels).long()\n",
    "\n",
    "# 拆分产生训练集、验证集和测试集\n",
    "pid = p_selected.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:800]).long()\n",
    "val_idx = torch.tensor(shuffle[800:900]).long()\n",
    "test_idx = torch.tensor(shuffle[900:]).long()\n",
    "\n",
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.2874, Train Acc 0.2663, Val Acc 0.3000 (Best 0.3000), Test Acc 0.2797 (Best 0.2797)\n",
      "Loss 1.0460, Train Acc 0.3837, Val Acc 0.3300 (Best 0.3300), Test Acc 0.3317 (Best 0.3317)\n",
      "Loss 0.8836, Train Acc 0.5688, Val Acc 0.4800 (Best 0.5100), Test Acc 0.5360 (Best 0.5226)\n",
      "Loss 0.7587, Train Acc 0.6175, Val Acc 0.4700 (Best 0.5100), Test Acc 0.5042 (Best 0.5226)\n",
      "Loss 0.6168, Train Acc 0.7800, Val Acc 0.5400 (Best 0.5400), Test Acc 0.5620 (Best 0.5620)\n",
      "Loss 0.4694, Train Acc 0.8575, Val Acc 0.6900 (Best 0.6900), Test Acc 0.6474 (Best 0.6474)\n",
      "Loss 0.3237, Train Acc 0.9588, Val Acc 0.7500 (Best 0.7500), Test Acc 0.7178 (Best 0.7178)\n",
      "Loss 0.2142, Train Acc 0.9825, Val Acc 0.7700 (Best 0.7900), Test Acc 0.7889 (Best 0.7764)\n",
      "Loss 0.1441, Train Acc 0.9962, Val Acc 0.7700 (Best 0.7900), Test Acc 0.7898 (Best 0.7764)\n",
      "Loss 0.1018, Train Acc 1.0000, Val Acc 0.7800 (Best 0.7900), Test Acc 0.7931 (Best 0.7764)\n",
      "Loss 0.0754, Train Acc 0.9987, Val Acc 0.7800 (Best 0.7900), Test Acc 0.7956 (Best 0.7764)\n",
      "Loss 0.0582, Train Acc 0.9975, Val Acc 0.7900 (Best 0.7900), Test Acc 0.7965 (Best 0.7764)\n",
      "Loss 0.0463, Train Acc 1.0000, Val Acc 0.7900 (Best 0.7900), Test Acc 0.7956 (Best 0.7764)\n",
      "Loss 0.0377, Train Acc 1.0000, Val Acc 0.7700 (Best 0.7900), Test Acc 0.7931 (Best 0.7764)\n",
      "Loss 0.0317, Train Acc 1.0000, Val Acc 0.7800 (Best 0.7900), Test Acc 0.7982 (Best 0.7764)\n",
      "Loss 0.0275, Train Acc 1.0000, Val Acc 0.8000 (Best 0.8000), Test Acc 0.7998 (Best 0.7973)\n",
      "Loss 0.0245, Train Acc 1.0000, Val Acc 0.8100 (Best 0.8100), Test Acc 0.8032 (Best 0.8032)\n",
      "Loss 0.0222, Train Acc 1.0000, Val Acc 0.8000 (Best 0.8100), Test Acc 0.8049 (Best 0.8032)\n",
      "Loss 0.0203, Train Acc 1.0000, Val Acc 0.8000 (Best 0.8100), Test Acc 0.8049 (Best 0.8032)\n",
      "Loss 0.0187, Train Acc 1.0000, Val Acc 0.7900 (Best 0.8100), Test Acc 0.8057 (Best 0.8032)\n"
     ]
    }
   ],
   "source": [
    "# 创建模型. 模型有三个输出，分别对应任务中的三个会议\n",
    "model = HeteroRGCN(G, 10, 10, 3)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    # 仅针对标记节点计算损失。\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "    val_acc = (pred[val_idx] == labels[val_idx]).float().mean()\n",
    "    test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
