{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value means srcID, dstID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch as th\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = h5py.File('./mesh_path.h5','r')\n",
    "f2 = h5py.File('./path_reac.h5','r')\n",
    "f3 = h5py.File('./reac_reac.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1 = f1['src']\n",
    "src2 = f2['src']\n",
    "src3 = f3['src']\n",
    "dis1 = f1['dis']\n",
    "dis2 = f2['dis']\n",
    "dis3 = f3['dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Graph(num_nodes={'meshDescriptor': 121, 'pathway': 209, 'reaction': 1277},\n      num_edges={('meshDescriptor', 'conclude', 'pathway'): 345, ('pathway', 'hasEvent', 'reaction'): 1289, ('reaction', 'precedingEvent', 'reaction'): 955, ('pathway', 'belong', 'meshDescriptor'): 345, ('reaction', 'eventOf', 'pathway'): 1289, ('reaction', 'laterEvent', 'reaction'): 955},\n      metagraph=[('meshDescriptor', 'pathway'), ('pathway', 'reaction'), ('pathway', 'meshDescriptor'), ('reaction', 'reaction'), ('reaction', 'reaction'), ('reaction', 'pathway')])"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "graph_data = {\n",
    "    ('meshDescriptor', 'conclude', 'pathway'): (th.tensor(src1), th.tensor(dis1)),\n",
    "    ('pathway', 'hasEvent', 'reaction'): (th.tensor(src2), th.tensor(dis2)),\n",
    "    ('reaction', 'precedingEvent', 'reaction'): (th.tensor(src3), th.tensor(dis3)),\n",
    "    ('pathway', 'belong', 'meshDescriptor'): (th.tensor(dis1), th.tensor(src1)),\n",
    "    ('reaction', 'eventOf', 'pathway'): (th.tensor(dis2), th.tensor(src2)),\n",
    "    ('reaction', 'laterEvent', 'reaction'): (th.tensor(dis3), th.tensor(src3))\n",
    "}\n",
    "G = dgl.heterograph(graph_data)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.nodes('pathway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Node types: ['meshDescriptor', 'pathway', 'reaction']\nEdge types: ['conclude', 'hasEvent', 'precedingEvent', 'belong', 'eventOf', 'laterEvent']\nCanonical edge types: [('meshDescriptor', 'conclude', 'pathway'), ('pathway', 'hasEvent', 'reaction'), ('reaction', 'precedingEvent', 'reaction'), ('pathway', 'belong', 'meshDescriptor'), ('reaction', 'eventOf', 'pathway'), ('reaction', 'laterEvent', 'reaction')]\n"
    }
   ],
   "source": [
    "print('Node types:', G.ntypes)\n",
    "print('Edge types:', G.etypes)\n",
    "print('Canonical edge types:', G.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<HDF5 dataset \"label_pathway\": shape (209,), type \"<i8\">"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "f4 = h5py.File('./label_path.h5','r')\n",
    "label_pathway = f4['label_pathway']\n",
    "label_pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([  0,   0, 117,   0, 117,  58,   0, 102,  14, 117, 117,   1,   2,  10,\n          2,  39,  40,  14,  74, 110,  26, 107,  14,  75,  11,  19,  73,  59,\n          8,  11,  62,   9,  62,  97,   9,   9,   9,   9,  12,  11,  28,  45,\n         11,  26,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  45,  26,\n         11,  11,  24,  11,  11,  45,  75,  11,  26,  86,  73,  11,  75,  11,\n         86,  14, 109,  14,  39, 100,  14,  58,  14,  14, 104,  19,  19,  31,\n        119,  21,  25,  25,  26,  26,  26,  26,  45,  28,  40,  28,  29,  33,\n         33,  33,  33,  75,  38,  39,  40, 102,  40,  40,  40,  63,  95,  41,\n         41,  43,  93,  97,  97,  49,  67,  53,  54,  89,  89,  57, 120,  58,\n         67,  58,  58, 103,  58,  58, 102,  69,  58,  60,  60,  62,  62,  62,\n         63,  65,  65,  65,  67,  67,  67,  67,  67,  67,  67,  67,  67,  67,\n         67,  67,  67,  67,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,\n         75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  93,  93,\n         78,  93,  85,  86,  93,  88,  88,  88,  91,  96,  96,  96,  97,  97,\n         97,  97,  97,  97,  98, 111, 111, 111, 102, 102, 104, 106, 108])"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "label_pathway = torch.tensor(label_pathway).long()\n",
    "len(label_pathway)\n",
    "labels = label_pathway\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = list(range(209))\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:180]).long()\n",
    "val_idx = torch.tensor(shuffle[160:200]).long()\n",
    "test_idx = torch.tensor(shuffle[200:]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "    def forward(self, G, feat_dict):\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # embedding layer for each nodes\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        return h_dict['pathway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss 5.2890, Train Acc 0.0389, Val Acc 0.0250 (Best 0.0250), Test Acc 0.0000 (Best 0.0000)\nLoss 4.9694, Train Acc 0.0500, Val Acc 0.0500 (Best 0.0500), Test Acc 0.0000 (Best 0.0000)\nLoss 4.5734, Train Acc 0.0500, Val Acc 0.0500 (Best 0.0500), Test Acc 0.0000 (Best 0.0000)\nLoss 4.0820, Train Acc 0.1167, Val Acc 0.1250 (Best 0.1250), Test Acc 0.1111 (Best 0.1111)\nLoss 3.5576, Train Acc 0.1833, Val Acc 0.1500 (Best 0.1500), Test Acc 0.1111 (Best 0.1111)\nLoss 3.0865, Train Acc 0.2167, Val Acc 0.2000 (Best 0.2000), Test Acc 0.1111 (Best 0.1111)\nLoss 2.6789, Train Acc 0.2222, Val Acc 0.2000 (Best 0.2000), Test Acc 0.1111 (Best 0.1111)\nLoss 2.2919, Train Acc 0.3778, Val Acc 0.3250 (Best 0.3250), Test Acc 0.2222 (Best 0.2222)\nLoss 1.9160, Train Acc 0.5389, Val Acc 0.4000 (Best 0.4000), Test Acc 0.2222 (Best 0.2222)\nLoss 1.5626, Train Acc 0.6667, Val Acc 0.3750 (Best 0.4000), Test Acc 0.2222 (Best 0.2222)\nLoss 1.2382, Train Acc 0.7778, Val Acc 0.5000 (Best 0.5000), Test Acc 0.2222 (Best 0.2222)\nLoss 0.9599, Train Acc 0.8278, Val Acc 0.5500 (Best 0.5500), Test Acc 0.2222 (Best 0.2222)\nLoss 0.7374, Train Acc 0.8722, Val Acc 0.5750 (Best 0.5750), Test Acc 0.2222 (Best 0.2222)\nLoss 0.5686, Train Acc 0.8778, Val Acc 0.6250 (Best 0.6250), Test Acc 0.2222 (Best 0.2222)\nLoss 0.4444, Train Acc 0.9167, Val Acc 0.6500 (Best 0.6500), Test Acc 0.3333 (Best 0.2222)\nLoss 0.3546, Train Acc 0.9278, Val Acc 0.6750 (Best 0.6750), Test Acc 0.4444 (Best 0.4444)\nLoss 0.2901, Train Acc 0.9333, Val Acc 0.7000 (Best 0.7000), Test Acc 0.5556 (Best 0.5556)\nLoss 0.2434, Train Acc 0.9444, Val Acc 0.7250 (Best 0.7250), Test Acc 0.5556 (Best 0.5556)\nLoss 0.2090, Train Acc 0.9556, Val Acc 0.7500 (Best 0.7500), Test Acc 0.5556 (Best 0.5556)\nLoss 0.1830, Train Acc 0.9722, Val Acc 0.7500 (Best 0.7500), Test Acc 0.5556 (Best 0.5556)\n"
    }
   ],
   "source": [
    "model = HeteroRGCN(G, 10, 10, 208)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "    val_acc = (pred[val_idx] == labels[val_idx]).float().mean()\n",
    "    test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "import scipy.io\n",
    "import urllib.request\n",
    "\n",
    "#data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "#data_file_path = '/tmp/ACM.mat'\n",
    "\n",
    "#urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat('./ACM.mat')\n",
    "print(list(data.keys()))\n",
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data['PvsA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n      num_edges={('paper', 'written-by', 'author'): 37055, ('author', 'writing', 'paper'): 37055, ('paper', 'citing', 'paper'): 30789, ('paper', 'cited', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('subject', 'has', 'paper'): 12499},\n      metagraph=[('author', 'paper'), ('paper', 'author'), ('paper', 'paper'), ('paper', 'paper'), ('paper', 'subject'), ('subject', 'paper')])\n"
    }
   ],
   "source": [
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'],\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'],\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'],\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose(),\n",
    "    })\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.nodes['paper'].data['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 graphviz创建元图.\n",
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')\n",
    "plot_graph(G.metagraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([    0,     1,     2, ..., 10805, 10806, 12420], dtype=int32)"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "pvc = data['PvsC'].tocsr()\n",
    "# 找到所有在 KDD, ICML, VLDB三个会议论文上发表的文章\n",
    "c_selected = [0, 11, 13]  # 三个数字分别代表KDD, ICML, VLDB\n",
    "p_selected = pvc[:, c_selected].tocoo() # 选出在\n",
    "\n",
    "# 生成标记\n",
    "labels = pvc.indices\n",
    "labels[labels == 11] = 1\n",
    "labels[labels == 13] = 2\n",
    "labels = torch.tensor(labels).long()\n",
    "\n",
    "# 拆分产生训练集、验证集和测试集\n",
    "pid = p_selected.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:800]).long()\n",
    "val_idx = torch.tensor(shuffle[800:900]).long()\n",
    "test_idx = torch.tensor(shuffle[900:]).long()\n",
    "\n",
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.nodes['paper'].data['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss 1.0725, Train Acc 0.4238, Val Acc 0.4800 (Best 0.4800), Test Acc 0.4146 (Best 0.4146)\nLoss 0.9391, Train Acc 0.4888, Val Acc 0.5700 (Best 0.5800), Test Acc 0.4690 (Best 0.5092)\nLoss 0.8118, Train Acc 0.5663, Val Acc 0.5300 (Best 0.5800), Test Acc 0.5151 (Best 0.5092)\nLoss 0.6347, Train Acc 0.8050, Val Acc 0.6500 (Best 0.6500), Test Acc 0.5955 (Best 0.5955)\nLoss 0.4281, Train Acc 0.9688, Val Acc 0.7400 (Best 0.7400), Test Acc 0.7010 (Best 0.7010)\nLoss 0.2608, Train Acc 0.9937, Val Acc 0.7800 (Best 0.8100), Test Acc 0.7563 (Best 0.7395)\nLoss 0.1545, Train Acc 0.9975, Val Acc 0.7800 (Best 0.8100), Test Acc 0.7613 (Best 0.7395)\nLoss 0.0938, Train Acc 1.0000, Val Acc 0.7700 (Best 0.8100), Test Acc 0.7621 (Best 0.7395)\nLoss 0.0619, Train Acc 1.0000, Val Acc 0.7500 (Best 0.8100), Test Acc 0.7513 (Best 0.7395)\nLoss 0.0462, Train Acc 1.0000, Val Acc 0.7400 (Best 0.8100), Test Acc 0.7446 (Best 0.7395)\nLoss 0.0378, Train Acc 1.0000, Val Acc 0.7200 (Best 0.8100), Test Acc 0.7420 (Best 0.7395)\nLoss 0.0328, Train Acc 1.0000, Val Acc 0.7200 (Best 0.8100), Test Acc 0.7471 (Best 0.7395)\nLoss 0.0293, Train Acc 1.0000, Val Acc 0.7300 (Best 0.8100), Test Acc 0.7462 (Best 0.7395)\nLoss 0.0263, Train Acc 1.0000, Val Acc 0.7300 (Best 0.8100), Test Acc 0.7513 (Best 0.7395)\nLoss 0.0238, Train Acc 1.0000, Val Acc 0.7200 (Best 0.8100), Test Acc 0.7521 (Best 0.7395)\nLoss 0.0214, Train Acc 1.0000, Val Acc 0.7200 (Best 0.8100), Test Acc 0.7521 (Best 0.7395)\nLoss 0.0193, Train Acc 1.0000, Val Acc 0.7100 (Best 0.8100), Test Acc 0.7546 (Best 0.7395)\nLoss 0.0176, Train Acc 1.0000, Val Acc 0.7100 (Best 0.8100), Test Acc 0.7529 (Best 0.7395)\nLoss 0.0163, Train Acc 1.0000, Val Acc 0.7000 (Best 0.8100), Test Acc 0.7513 (Best 0.7395)\nLoss 0.0152, Train Acc 1.0000, Val Acc 0.7100 (Best 0.8100), Test Acc 0.7638 (Best 0.7395)\n"
    }
   ],
   "source": [
    "# 创建模型. 模型有三个输出，分别对应任务中的三个会议\n",
    "model = HeteroRGCN(G, 10, 10, 3)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    # 仅针对标记节点计算损失。\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "    val_acc = (pred[val_idx] == labels[val_idx]).float().mean()\n",
    "    test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}